# -*- coding: utf-8 -*-
"""Statistical_Analysis-Mask_4095 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cm6TYYHZapP7kexZTKZfhGzszl4fcLww
"""

import hashlib
import secrets
import matplotlib.pyplot as plt
from scipy.stats import chisquare

from collections import *

def shake_generate_input(seed: bytes, length):
    """
    Generate input bytes using SHAKE-128.

    Parameters:
    - seed (bytes): The seed input to SHAKE-128
    - length (int): The number of output bytes required (default: 384 bytes for Kyber512)

    Returns:
    - bytes: The generated pseudo-random byte string.
    """
    shake = hashlib.shake_128()
    shake.update(seed)
    return shake.digest(length)  # Generate 'length' bytes

def modified_sample_ntt(byte_stream, poly_size):
    """
    Generates polynomial coefficients mod q using a mapping strategy.

    :param byte_stream: Source of uniform random bytes.
    :param q: Prime modulus for the finite field.
    :param poly_size: Number of polynomial coefficients.
    :return: Polynomial coefficients mod q.
    """
    q=3329
    i = 0
    j = 0
    poly_coeffs = [0] * poly_size
    q_bits = q.bit_length()
    #print(q)
    max_value = (1 << q_bits)
    mask = max_value - 1
    #print(mask)
    while j < poly_size:
        if i + 1 >= len(byte_stream):
            raise ValueError("Insufficient byte stream length")

        b1, b2 = byte_stream[i:i+2]

        d1 = (b1 | (b2 << 8)) & mask
        d2 = (b2 | (b1 << 8)) & mask
        #print(d1)
        #print(d2)
        #d1 = (d1 & t)
        #d2 = (d2 & t)
        #print(d1)
        #print(d2)



        if d1 < 3329:
                poly_coeffs[j] = d1
                j = j + 1

        if d2 < 3329 and j < poly_size:
                poly_coeffs[j] = d2
                j = j + 1

        i += 2

    return poly_coeffs


def sample_ntt(byte_stream, poly_size):
        """
        Algorithm 1 (Parse)
        https://pq-crystals.org/kyber/data/kyber-specification-round3-20210804.pdf

        Algorithm 6 (Sample NTT)

        Parse: B^* -> R
        """
        i, j = 0, 0
        coefficients = [0 for i in range(poly_size)]
        while j < poly_size:
            d1 = byte_stream[i] + 256 * (byte_stream[i + 1] % 16)
            d2 = (byte_stream[i + 1] // 16) + 16 * byte_stream[i + 2]
            #print(i+2)
            if d1 < 3329:
                coefficients[j] = d1
                j = j + 1

            if d2 < 3329 and j < poly_size:
                coefficients[j] = d2
                j = j + 1

            i = i + 3
        #print('final', i)
        return coefficients

def parse_spdm3(byte_stream, poly_size):
    q=3329
    i = 0
    j = 0
    a_hat = []

    while j < poly_size:
        d1 = 16 * byte_stream[i] + (byte_stream[i + 1] // 16)

        if d1 < 3584:
            i += 1

        d2 = (256 * byte_stream[i] % (2 ** 12)) + byte_stream[i + 1]

        if d1 < q:
            a_hat.append(d1)
            j += 1

        if d2 < q and j < poly_size:
            a_hat.append(d2)
            j += 1

        if d2 < 3584:
            i += 2
        else:
            i += 1

    return a_hat

byte_stream = shake_generate_input(seed = secrets.token_bytes(32), length=600)
poly_size=256

a=modified_sample_ntt(byte_stream, poly_size)
print(len(a))

coeff_ours=modified_sample_ntt(byte_stream, poly_size)
coeff_kyber=sample_ntt(byte_stream, poly_size)
coeff_korean=parse_spdm3(byte_stream, poly_size)
print(len(coeff_ours))
print(len(coeff_kyber))
print(len(coeff_korean))

seed_list=[]
for i in range(100000):
    seed_list.append(shake_generate_input(seed = secrets.token_bytes(32), length=600))
print(len(seed_list))
#print(len(seed_list[0]))

list_coeff_ours=[]
list_coeff_kyber=[]
list_coeff_korean=[]
for seed in seed_list:
    list_coeff_ours.append(modified_sample_ntt(seed, poly_size))
print(len(list_coeff_ours))

for seed in seed_list:
    list_coeff_kyber.append(sample_ntt(seed, poly_size))
print(len(list_coeff_kyber))

for seed in seed_list:
    list_coeff_korean.append(parse_spdm3(seed, poly_size))
print(len(list_coeff_korean))

flattened_list_ours = [item for sublist in list_coeff_ours for item in sublist]
print(len(flattened_list_ours))

flattened_list_kyber = [item for sublist in list_coeff_kyber for item in sublist]
print(len(flattened_list_kyber))

flattened_list_korean = [item for sublist in list_coeff_korean for item in sublist]
print(len(flattened_list_korean))

def frequency_test(data, num_bins=3329):
    observed_counts = Counter(data)
    frequencies = np.array(list(observed_counts.values()))
    std_dev = np.std(frequencies)
    mean_freq = np.mean(frequencies)
    #print(len(data))
    print(f"Frequency Test: Mean = {mean_freq:.2f}, Std Dev = {std_dev:.2f}")




import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import chi2

def frequency_chi_square_test(data, value_range, alpha=0.05):
    """
    Performs Frequency Test and Chi-Square Test on a sequence of integers.

    Parameters:
        data (list): Sequence of integers.
        value_range (int): Number of distinct possible values (e.g., 3330 for [0, 3329]).
        alpha (float): Significance level for hypothesis testing.

    Returns:
        dict: Dictionary containing test statistics and interpretation.
    """
    N = len(data)
    k = value_range
    expected_freq = N / k

    # Count observed frequencies
    observed_counts = np.zeros(k, dtype=int)
    for val in data:
        observed_counts[val] += 1

    # Standard deviation of observed frequencies
    std_dev = np.sqrt(np.sum((observed_counts - expected_freq) ** 2) / k)

    # Chi-square statistic
    chi_square_stat = np.sum((observed_counts - expected_freq) ** 2 / expected_freq)
    p_value = 1 - chi2.cdf(chi_square_stat, df=k-1)

    # Result interpretation
    result = "PASS" if p_value > alpha else "FAIL"

    # Print summary
    print(f"--- Frequency + Chi-Square Test ---")
    print(f"Total samples (N): {N}")
    print(f"Value range (k): {k}")
    print(f"Expected frequency: {expected_freq:.4f}")
    print(f"Standard deviation: {std_dev:.4f}")
    print(f"Chi-Square statistic: {chi_square_stat:.4f}")
    print(f"p-value: {p_value:.6f}")
    print(f"Result at alpha={alpha}: {result}")

"""Result for Our Sampler for flattended list of 256*100000 list"""

print('Ours Result')
frequency_test(flattened_list_ours,num_bins=3329)
frequency_chi_square_test(flattened_list_ours,3329)
print('\n')

print('Ours Result')
frequency_test(flattened_list_kyber,num_bins=3329)
frequency_chi_square_test(flattened_list_kyber,3329)
print('\n')
print('Ours Result')
frequency_test(flattened_list_korean,num_bins=3329)
frequency_chi_square_test(flattened_list_korean,3329)

"""Below test is not needed as the flattend list containst coeffs geenrated from 1 Lak"""

# import io
# from contextlib import redirect_stdout

# with open("chi_square_results.txt_ours", "w") as file:
#     for i in range(100000):
#         f = io.StringIO()
#         with redirect_stdout(f):
#             frequency_chi_square_test(list_coeff_ours[i], 3329)
#         output = f.getvalue()
#         file.write(f"Test {i}:\n{output}\n")


# import io
# from contextlib import redirect_stdout

# with open("chi_square_results.txt_kyber", "w") as file:
#     for i in range(100000):
#         f = io.StringIO()
#         with redirect_stdout(f):
#             frequency_chi_square_test(list_coeff_kyber[i], 3329)
#         output = f.getvalue()
#         file.write(f"Test {i}:\n{output}\n")



# import io
# from contextlib import redirect_stdout

# with open("chi_square_results.txt_korean", "w") as file:
#     for i in range(100000):
#         f = io.StringIO()
#         with redirect_stdout(f):
#             frequency_chi_square_test(list_coeff_korean[i], 3329)
#         output = f.getvalue()
#         file.write(f"Test {i}:\n{output}\n")

# pass_count = 0
# fail_count = 0

# with open("chi_square_results.txt_ours", "r") as file:
#     for line in file:
#         if "Result at alpha=0.05:" in line:
#             if "PASS" in line:
#                 pass_count += 1
#             elif "FAIL" in line:
#                 fail_count += 1

# print(f"Total PASS: {pass_count}")
# print(f"Total FAIL: {fail_count}")

# print('\n')
# pass_count = 0
# fail_count = 0

# with open("chi_square_results.txt_kyber", "r") as file:
#     for line in file:
#         if "Result at alpha=0.05:" in line:
#             if "PASS" in line:
#                 pass_count += 1
#             elif "FAIL" in line:
#                 fail_count += 1

# print(f"Total PASS: {pass_count}")
# print(f"Total FAIL: {fail_count}")

# print('\n')

# pass_count = 0
# fail_count = 0

# with open("chi_square_results.txt_korean", "r") as file:
#     for line in file:
#         if "Result at alpha=0.05:" in line:
#             if "PASS" in line:
#                 pass_count += 1
#             elif "FAIL" in line:
#                 fail_count += 1

# print(f"Total PASS: {pass_count}")
# print(f"Total FAIL: {fail_count}")





"""Entropy Test"""

from collections import Counter
import numpy as np
def entropy_test(data, num_bins=3329):
    observed_counts = Counter(data)
    probabilities = np.array(list(observed_counts.values())) / len(data)
    entropy = -np.sum(probabilities * np.log2(probabilities))
    expected_entropy = np.log2(num_bins)

    print(f"Entropy Test: H = {entropy:.4f}, Expected H = {expected_entropy:.4f}")
    return entropy, expected_entropy
print('Our Results')
entropy_test(flattened_list_ours, num_bins=3329)
print('\n')
print('Kyber Results')
entropy_test(flattened_list_kyber, num_bins=3329)
print('\n')
print('Korean Results')
entropy_test(flattened_list_korean, num_bins=3329)

"""The Kolmogorov-Smirnov (KS) test statistic
https://www.geeksforgeeks.org/kolmogorov-smirnov-test-ks-test/
"""

from scipy.stats import kstest

# Example: normalize your data between 0 and 1
normalized_data = [x / 3329 for x in flattened_list_ours[:100000]]
statistic, p_value = kstest(normalized_data, 'uniform')

print("KS Statistic:", statistic)
print("p-value:", p_value)

# Example: normalize your data between 0 and 1
normalized_data = [x / 3329 for x in flattened_list_kyber[:100000]]
statistic, p_value = kstest(normalized_data, 'uniform')

print("KS Statistic:", statistic)
print("p-value:", p_value)

# Example: normalize your data between 0 and 1
normalized_data = [x / 3329 for x in flattened_list_korean[:100000]]
statistic, p_value = kstest(normalized_data, 'uniform')

print("KS Statistic:", statistic)
print("p-value:", p_value)

"""Runs Test (Wald-Wolfowitz Test)"""

import numpy as np
from scipy.stats import norm

def runs_test(data):
    # Step 1: Convert to binary sequence using median threshold
    median = np.median(data)
    binary_seq = [1 if x > median else 0 for x in data]

    # Step 2: Count number of runs
    runs = 1  # at least one run exists
    for i in range(1, len(binary_seq)):
        if binary_seq[i] != binary_seq[i-1]:
            runs += 1

    n1 = binary_seq.count(1)
    n0 = binary_seq.count(0)
    n = n1 + n0

    # Step 3: Compute expected runs and standard deviation
    expected_runs = (2 * n1 * n0) / n + 1
    variance_runs = (2 * n1 * n0 * (2 * n1 * n0 - n)) / (n**2 * (n - 1))

    # Step 4: Compute Z-score
    z = (runs - expected_runs) / np.sqrt(variance_runs)
    p_value = 2 * (1 - norm.cdf(abs(z)))  # two-tailed

    # Output results
    print(f"Runs: {runs}")
    print(f"Expected Runs: {expected_runs:.4f}")
    print(f"Z-score: {z:.4f}")
    print(f"p-value: {p_value:.4f}")

    if p_value < 0.05:
        print("Result: Sequence is likely NOT random.")
    else:
        print("Result: Sequence may be random.")

print('Ours')
runs_test(flattened_list_ours[:1000000])
print('\n')

print('Kyber')
runs_test(flattened_list_kyber[:1000000])
print('\n')

print('Korean')
runs_test(flattened_list_korean[:1000000])
print('\n')

def serial_test(data, num_bins=3330):
    pairs = list(zip(data[:-1], data[1:]))  # Create (x, y) pairs
    observed_counts = Counter(pairs)

    expected = len(data) / (num_bins**2)  # Expected frequency per pair
    observed_freq = np.array(list(observed_counts.values()))

    chi_stat, p_value = chisquare(observed_freq, [expected] * len(observed_freq))

    print(f"Serial Test: χ² = {chi_stat:.2f}, p-value = {p_value:.5f}")
    return chi_stat, p_value

import numpy as np
from scipy.stats import chi2
from collections import defaultdict

def serial_test(sequence, k):
    n = len(sequence)
    expected = (n - 1) / (k * k)

    # Count observed frequencies of each pair (x_i, x_{i+1})
    pair_counts = defaultdict(int)
    for i in range(n - 1):
        a, b = sequence[i], sequence[i + 1]
        pair_counts[(a, b)] += 1

    # Compute Chi-square statistic
    chi_square = 0
    for i in range(k):
        for j in range(k):
            observed = pair_counts.get((i, j), 0)
            chi_square += ((observed - expected) ** 2) / expected

    # Degrees of freedom = k^2 - 1
    #dof = k * k - 1
    p_value = 1 - chi2.cdf(chi_square, dof)

    # Output
    print(f"Chi-square statistic: {chi_square:.4f}")
    #print(f"Degrees of freedom: {dof}")
    print(f"P-value: {p_value:.6f}")

    if p_value < 0.05:
        print("Result: Sequence may NOT be random.")
    else:
        print("Result: Sequence appears random.")

for seed in seed_list[1:1000]:

    print('Ours')
    serial_test(modified_sample_ntt(seed, poly_size),3329)
    print('\n')

    print('Kyber')
    serial_test(sample_ntt(seed, poly_size),3329)
    print('\n')

    print('Korean')
    serial_test(parse_spdm3(seed, poly_size),3329)
    print('\n')

import numpy as np
from scipy.stats import chi2
from collections import defaultdict

# Store pass counts
pass_count = {'Ours': 0, 'Kyber': 0, 'Korean': 0}

# Store logs
log_lines = []

def serial_test(sequence, k):
    n = len(sequence)
    expected = (n - 1) / (k * k)
    pair_counts = defaultdict(int)

    for i in range(n - 1):
        a, b = sequence[i], sequence[i + 1]
        pair_counts[(a, b)] += 1

    chi_square = 0
    for i in range(k):
        for j in range(k):
            observed = pair_counts.get((i, j), 0)
            chi_square += ((observed - expected) ** 2) / expected

    dof = k * k - 1
    p_value = 1 - chi2.cdf(chi_square, dof)
    return chi_square, p_value


# Loop through seeds and collect results
for seed in seed_list[1:100]:
    for scheme_name, scheme_func in [('Ours', modified_sample_ntt), ('Kyber', sample_ntt), ('Korean', parse_spdm3)]:
        sequence = scheme_func(seed, poly_size)
        chi_sq, p_val = serial_test(sequence, 3329)

        passed = p_val >= 0.05
        if passed:
            pass_count[scheme_name] += 1

        # Prepare log line
        log_line = f"{scheme_name} | Seed: {seed} | Chi-square: {chi_sq:.4f} | p-value: {p_val:.6f} | {'PASS' if passed else 'FAIL'}"
        log_lines.append(log_line)
        #print(log_line)

# Save results to a file
with open("serial_test_results.txt", "w") as f:
    f.write("\n".join(log_lines))
    f.write("\n\nSummary:\n")
    for scheme in pass_count:
        f.write(f"{scheme}: {pass_count[scheme]} passed out of 999 tests\n")

# Also print summary
print("\nSummary:")
for scheme in pass_count:
    print(f"{scheme}: {pass_count[scheme]} passed out of 999 tests")

